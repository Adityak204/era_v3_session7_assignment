{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/era_v3/era_v3_session7_assignment'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/ubuntu/era_v3/era_v3_session7_assignment/')\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(train_loader)\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss += loss.item() * data.size(0)  # accumulate batch loss\n",
    "        \n",
    "        # Backward pass and optimizer step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_description(desc=f\"loss={loss.item():.4f} batch_id={batch_idx}\")\n",
    "\n",
    "    # Compute average loss and accuracy for the epoch\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    accuracy = 100.0 * correct / total\n",
    "\n",
    "    print(f\"\\nEpoch {epoch}: Train set: Average loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({accuracy:.2f}%)\\n\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # Compute loss\n",
    "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()\n",
    "            \n",
    "            # Compute accuracy\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # Compute average loss and accuracy for the test set\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## Checking if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking number of cores available\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 134MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 12.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 125MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(42)\n",
    "batch_size = 1024\n",
    "kwargs = {'num_workers': 8, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                        transforms.RandomAffine(\n",
    "                            degrees=15,  # Random rotation up to 10 degrees\n",
    "                        ),                        \n",
    "                        transforms.RandomErasing(p=0.1),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniCNN_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniCNN_3, self).__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, out_channels=8, kernel_size=(3, 3), padding=1, bias=False\n",
    "            ),  # 28,1>28,8|RF:3,J:1\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=8, out_channels=8, kernel_size=(3, 3), padding=1, bias=False\n",
    "            ),  # 28,8>28,8|RF:5,J:1\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=8,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),  # 28,8>28,16|RF:7,J:1\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.pool_1 = nn.MaxPool2d(2, 2)  # 28,16>14,16|RF:8,J:2\n",
    "        self.transition_1 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=4, kernel_size=(1, 1), padding=0, bias=False\n",
    "        )  # 14,16>14,8|RF:8,J:2\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=4, out_channels=8, kernel_size=(3, 3), padding=1, bias=False\n",
    "            ),  # 14,8>14,8|RF:12,J:2\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=8,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),  # 14,8>14,16|RF:16,J:2\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),  # 14,16>14,16|RF:20,J:2\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.pool_2 = nn.MaxPool2d(2, 2)  # 14,16>7,16|RF:21,J:4\n",
    "        self.transition_2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=4, kernel_size=(1, 1), padding=0, bias=False\n",
    "        )  # 14,16>7,4|RF:21,J:4\n",
    "        self.fc = nn.Linear(4 * 7 * 7, 10)  # 7,4>10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block_1(x)\n",
    "        x = self.pool_1(x)\n",
    "        x = self.transition_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.pool_2(x)\n",
    "        x = self.transition_2(x)\n",
    "        x = x.view(-1, 4 * 7 * 7)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              72\n",
      "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
      "              ReLU-3            [-1, 8, 28, 28]               0\n",
      "            Conv2d-4            [-1, 8, 28, 28]             576\n",
      "       BatchNorm2d-5            [-1, 8, 28, 28]              16\n",
      "              ReLU-6            [-1, 8, 28, 28]               0\n",
      "            Conv2d-7           [-1, 16, 28, 28]           1,152\n",
      "       BatchNorm2d-8           [-1, 16, 28, 28]              32\n",
      "              ReLU-9           [-1, 16, 28, 28]               0\n",
      "          Dropout-10           [-1, 16, 28, 28]               0\n",
      "        MaxPool2d-11           [-1, 16, 14, 14]               0\n",
      "           Conv2d-12            [-1, 4, 14, 14]              64\n",
      "           Conv2d-13            [-1, 8, 14, 14]             288\n",
      "      BatchNorm2d-14            [-1, 8, 14, 14]              16\n",
      "             ReLU-15            [-1, 8, 14, 14]               0\n",
      "           Conv2d-16           [-1, 16, 14, 14]           1,152\n",
      "      BatchNorm2d-17           [-1, 16, 14, 14]              32\n",
      "             ReLU-18           [-1, 16, 14, 14]               0\n",
      "           Conv2d-19           [-1, 16, 14, 14]           2,304\n",
      "      BatchNorm2d-20           [-1, 16, 14, 14]              32\n",
      "             ReLU-21           [-1, 16, 14, 14]               0\n",
      "          Dropout-22           [-1, 16, 14, 14]               0\n",
      "        MaxPool2d-23             [-1, 16, 7, 7]               0\n",
      "           Conv2d-24              [-1, 4, 7, 7]              64\n",
      "           Linear-25                   [-1, 10]           1,970\n",
      "================================================================\n",
      "Total params: 7,786\n",
      "Trainable params: 7,786\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.91\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = MiniCNN_3().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Epoch = 1 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.1870 batch_id=58: 100%|██████████| 59/59 [00:30<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Train set: Average loss: 0.3856, Accuracy: 52828/60000 (88.05%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0768, Accuracy: 9765/10000 (97.65%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 2 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0896 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Train set: Average loss: 0.1262, Accuracy: 57600/60000 (96.00%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0573, Accuracy: 9831/10000 (98.31%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 3 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0878 batch_id=58: 100%|██████████| 59/59 [00:12<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Train set: Average loss: 0.1006, Accuracy: 58078/60000 (96.80%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0559, Accuracy: 9826/10000 (98.26%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 4 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.1152 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Train set: Average loss: 0.0923, Accuracy: 58166/60000 (96.94%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0454, Accuracy: 9865/10000 (98.65%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 5 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0687 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Train set: Average loss: 0.0844, Accuracy: 58383/60000 (97.31%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0388, Accuracy: 9867/10000 (98.67%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 6 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0731 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Train set: Average loss: 0.0789, Accuracy: 58462/60000 (97.44%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0382, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 7 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0570 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Train set: Average loss: 0.0749, Accuracy: 58505/60000 (97.51%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 8 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0520 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Train set: Average loss: 0.0715, Accuracy: 58588/60000 (97.65%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 9917/10000 (99.17%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 9 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0654 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Train set: Average loss: 0.0678, Accuracy: 58641/60000 (97.73%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 9917/10000 (99.17%)\n",
      "\n",
      "LR =  [0.01]\n",
      "********* Epoch = 10 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0674 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Train set: Average loss: 0.0676, Accuracy: 58660/60000 (97.77%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "LR =  [0.001]\n",
      "********* Epoch = 11 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0554 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: Train set: Average loss: 0.0552, Accuracy: 58913/60000 (98.19%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 9936/10000 (99.36%)\n",
      "\n",
      "LR =  [0.001]\n",
      "********* Epoch = 12 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0657 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: Train set: Average loss: 0.0517, Accuracy: 58984/60000 (98.31%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 9933/10000 (99.33%)\n",
      "\n",
      "LR =  [0.001]\n",
      "********* Epoch = 13 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0367 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: Train set: Average loss: 0.0508, Accuracy: 58994/60000 (98.32%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 9942/10000 (99.42%)\n",
      "\n",
      "LR =  [0.001]\n",
      "********* Epoch = 14 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0445 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: Train set: Average loss: 0.0484, Accuracy: 59031/60000 (98.39%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 9939/10000 (99.39%)\n",
      "\n",
      "LR =  [0.001]\n",
      "********* Epoch = 15 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0502 batch_id=58: 100%|██████████| 59/59 [00:13<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: Train set: Average loss: 0.0474, Accuracy: 59047/60000 (98.41%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 9939/10000 (99.39%)\n",
      "\n",
      "LR =  [0.0001]\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"max\",\n",
    "    factor=0.1,\n",
    "    patience=1,\n",
    "    verbose=True,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "for epoch in range(1, 16):\n",
    "    print(f\"********* Epoch = {epoch} *********\")\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    _, acc = test(model, device, test_loader)\n",
    "    scheduler.step(acc)\n",
    "    print(\"LR = \", scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EC2 details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 13 11:34:10 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   30C    P0             31W /   70W |     773MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      9840      C   /opt/conda/envs/pytorch/bin/python3.11        770MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# dmidecode 3.3\n",
      "Getting SMBIOS data from sysfs.\n",
      "SMBIOS 2.7 present.\n",
      "\n",
      "Handle 0x0000, DMI type 0, 24 bytes\n",
      "BIOS Information\n",
      "\tVendor: Amazon EC2\n",
      "\tVersion: 1.0\n",
      "\tRelease Date: 10/16/2017\n",
      "\tAddress: 0xF0000\n",
      "\tRuntime Size: 64 kB\n",
      "\tROM Size: 64 kB\n",
      "\tCharacteristics:\n",
      "\t\tPCI is supported\n",
      "\t\tEDD is supported\n",
      "\t\tACPI is supported\n",
      "\t\tSystem is a virtual machine\n",
      "\tBIOS Revision: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sudo dmidecode -t bios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
